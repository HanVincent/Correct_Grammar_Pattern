{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from operator import itemgetter\n",
    "from Bio import pairwise2\n",
    "from utils.syntax import *\n",
    "from utils.counts import *\n",
    "import numpy as np\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # ('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read patterns/sents json file\n",
    "with open('coca.json', 'r', encoding='utf8') as fs:\n",
    "    BNC = json.load(fs)\n",
    "    patterns, sents, ngrams = BNC['patterns'], BNC['sents'], BNC['ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ptn):\n",
    "    if 'be V-ed' in ptn: print(ptn) # 先不管被動用法\n",
    "            \n",
    "    ptn = 'V' + ptn.split('V')[1] # 去頭 (headword 之前的)\n",
    "    ptn = ' '.join(ptn.split(' ')[:4]) # max lenght: 4-gram\n",
    "    ptn = ptn.replace('V-ing', 'V').replace('V-ed', 'V') # 除了被動外，完成式和進行式改成原 V\n",
    "    # ptn = ptn.replace('wh-cl', 'O').replace('cl', 'O') # cl / wh-cl -> O\n",
    "    # ptn = ptn.replace('to-v', 'ADJ').replace('v-ing', 'ADJ') # v-ing / to-v -> ?\n",
    "        \n",
    "    # if / which / who / whom\n",
    "    # TODO: 還要修改條件？\n",
    "    ptn = ptn.split(' ')\n",
    "    if len(ptn) > 2:\n",
    "        if ptn[1] in PREPOSITIONS: # V prep. _\n",
    "            ptn = ptn[:3]\n",
    "        elif ptn[1] != 'O': # V before O\n",
    "            ptn = ptn[:1]\n",
    "        elif ptn[2] in PREPOSITIONS: # V O prep. O\n",
    "            ptn = ptn[:4]\n",
    "        else: # V O O / V O not_prep\n",
    "            ptn = ptn[:2]\n",
    "    return ' '.join(ptn)\n",
    "\n",
    "\n",
    "norm_patterns = defaultdict(lambda: defaultdict(Counter))\n",
    "norm_ngrams = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: [])))\n",
    "norm_sents = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: [])))\n",
    "\n",
    "for headword in patterns:\n",
    "    for dep in patterns[headword]:\n",
    "        for ptn in patterns[headword][dep]:\n",
    "            norm_patterns[headword][dep][normalize(ptn)] += patterns[headword][dep][ptn]\n",
    "            norm_ngrams[headword][dep][normalize(ptn)].extend(ngrams[headword][dep][ptn])\n",
    "            norm_sents[headword][dep][normalize(ptn)].extend(sents[headword][dep][ptn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 ptn / first_ptn 百分比\n",
    "def predict_ratio(ptn, patterns):\n",
    "    if ptn not in patterns: \n",
    "        return 0\n",
    "    return patterns[ptn] / patterns[max(patterns, key=patterns.get)]\n",
    "    \n",
    "CONFIDENT, UNCONFIDENT = 0.2, 0.1\n",
    "\n",
    "def categorize(ratio):\n",
    "    if ratio > CONFIDENT:     return 'right'\n",
    "    elif ratio < UNCONFIDENT: return 'wrong'\n",
    "    else:                     return 'not_sure'\n",
    "    \n",
    "    \n",
    "def get_template(ratio):\n",
    "    if ratio > CONFIDENT:     return '{{+{}+}}'\n",
    "    elif ratio < UNCONFIDENT: return '[-{}-]'\n",
    "    else:                     return '\\\\*{}*\\\\'\n",
    "    \n",
    "    \n",
    "def suggest_ptn(bad_ptn, ptns):\n",
    "    ptns = truncate_k(ptns, ptns[bad_ptn]) if bad_ptn in ptns else ptns # Optimize if exist\n",
    "\n",
    "    sim_ptns = sorted(ptns, key=ptns.get, reverse=True)\n",
    "    sim_ptns = sorted(sim_ptns, key=lambda ptn: edit_distance(bad_ptn.split(' '), ptn.split(' ')))\n",
    "    \n",
    "#     print(sim_ptns[:5])\n",
    "    \n",
    "    return sim_ptns[0]\n",
    "\n",
    "\n",
    "def suggest_ngram(ngram, ngrams):\n",
    "    ngrams = filter(lambda ng: '@@@' not in ng, set(ngrams)) # workaround\n",
    "    ngram = ngram.lower()\n",
    "\n",
    "    sim_ngrams = sorted(ngrams, key=lambda ng: edit_distance(ngram.split(' '), ng.split(' ')))\n",
    "    \n",
    "#     print(sim_ngrams[:5])\n",
    "    \n",
    "    return sim_ngrams[0]\n",
    "\n",
    "\n",
    "def edit_ngram(tk, ngram_list, old_ptn, new_ptn):\n",
    "    edit_ngram_list = [ng.text for ng in ngram_list]\n",
    "    old_ptn, new_ptn = old_ptn.split(' '), new_ptn.split(' ')\n",
    "    align = pairwise2.align.globalxs(old_ptn, new_ptn, -10, -0.5, gap_char=['_'])[0]\n",
    "    anchor = [i for i, ng in enumerate(ngram_list) if ng.i == tk.i][0]\n",
    "    \n",
    "    for i, tag in enumerate(align[1]):\n",
    "        if tag in ['S', 'V', 'O']: \n",
    "            pass\n",
    "        elif tag in PREPOSITIONS and edit_ngram_list[i+anchor] in PREPOSITIONS: \n",
    "            edit_ngram_list[i + anchor] = tag\n",
    "        elif tag in PREPOSITIONS:\n",
    "            edit_ngram_list[i + anchor] = tag + ' ' + edit_ngram_list[i + anchor]\n",
    "        elif tag == '_': \n",
    "            edit_ngram_list[i + anchor] = None\n",
    "        else:\n",
    "            print(\"Not here:\", tag)\n",
    "\n",
    "    return ' '.join([ng for ng in edit_ngram_list if ng])\n",
    "\n",
    "\n",
    "def edit_sentence():\n",
    "    pass\n",
    "\n",
    "\n",
    "def correct(line):\n",
    "    line = nlp(line)\n",
    "    \n",
    "    edits, suggestions, edit_line = [], [], [tk.text for tk in line]\n",
    "    for tk in line:\n",
    "        if tk.tag_ in POS['VERBS']:\n",
    "            # 以下拆 def ?\n",
    "            ptns, ngrams = dep_to_ptns_ngrams(tk)\n",
    "            ptn, ngram = ' '.join(ptns), ' '.join([ng.text for ng in ngrams])\n",
    "            # print(\"ptn: {}, ngram: {}\".format(ptn, ngram))\n",
    "            \n",
    "            norm_ptn = normalize(ptn)\n",
    "            ptns = norm_patterns[tk.lemma_][tk.dep_]\n",
    "            # high_ptns  = get_high_freq(ptns)\n",
    "            \n",
    "            ratio = predict_ratio(norm_ptn, ptns)\n",
    "            # print(tk.text, tk.dep_, norm_ptn, ratio)\n",
    "        \n",
    "            if ratio < CONFIDENT:\n",
    "                top_ptn = suggest_ptn(norm_ptn, ptns)\n",
    "                top_ngram = suggest_ngram(ngram, norm_ngrams[tk.lemma_][tk.dep_][top_ptn])\n",
    "                new_ngram = edit_ngram(tk, ngrams, norm_ptn, top_ptn)\n",
    "            \n",
    "                suggestions.append({\n",
    "                    'category': categorize(ratio),\n",
    "                    'tk': tk.text,\n",
    "                    'bef': norm_ptn,\n",
    "                    'aft': top_ptn,\n",
    "                    'ngram': new_ngram\n",
    "                    # 'ngram': top_ngram\n",
    "                })\n",
    "\n",
    "            edits.append(get_template(ratio).format(tk.text))\n",
    "        else:\n",
    "            edits.append(tk.text)\n",
    "   \n",
    "    return ' '.join(edits), suggestions\n",
    "\n",
    "def main_process(content):\n",
    "    edit_lines, suggestions = [], []\n",
    "\n",
    "    for line in content.split('\\n'):\n",
    "        edit, sug = correct(line)\n",
    "        \n",
    "        edit_lines.append(edit)\n",
    "        suggestions.extend(sug)\n",
    "\n",
    "    return edit_lines, suggestions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['can you [-rely-] heavily in my life in last July without hestitation ?'],\n",
      " [{'aft': 'V on O',\n",
      "   'bef': 'V in O',\n",
      "   'category': 'wrong',\n",
      "   'ngram': 'can you rely on life in July without hestitation',\n",
      "   'tk': 'rely'}])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from pprint import pprint\n",
    "#     user_input = '''I want to discuss exaggerately about my life. I rely my ability.'''\n",
    "    user_input = 'can you rely heavily in my life in last July without hestitation?'\n",
    "    pprint(main_process(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:1314/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS, cross_origin\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "# post /correct data: {content :}\n",
    "@app.route('/correct' , methods=['POST'])\n",
    "def start_correct():\n",
    "    request_data = request.get_json()\n",
    "    if not request_data: return jsonify({'edit': 'Should not be empty'})\n",
    "    \n",
    "    content = request_data['content']\n",
    "    print(content)\n",
    "    \n",
    "    edits, suggestions = main_process(content)\n",
    "    \n",
    "    return jsonify({\n",
    "        'edits': edits,\n",
    "        'suggestions': suggestions\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=1314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V on O', 3342),\n",
       " ('V upon O', 138),\n",
       " ('V on cl', 91),\n",
       " ('V', 37),\n",
       " ('V O', 27),\n",
       " ('V on wh-cl', 26),\n",
       " ('V on v-ing', 12),\n",
       " ('V to O', 11),\n",
       " ('V for O', 10),\n",
       " ('V on', 9),\n",
       " ('V cl', 8),\n",
       " ('V O on O', 6),\n",
       " ('V in O', 5),\n",
       " ('V with O', 2),\n",
       " ('V upon', 2),\n",
       " ('V on v', 2),\n",
       " ('V at O', 2),\n",
       " ('V upon cl', 2),\n",
       " ('V to-v', 1),\n",
       " ('V in cl', 1),\n",
       " ('V by O', 1),\n",
       " ('V v', 1),\n",
       " ('V upon v', 1),\n",
       " ('V upon wh-cl', 1),\n",
       " ('V upon v-ing', 1),\n",
       " ('V on to-v', 1),\n",
       " ('V in on', 1),\n",
       " ('V on v-ed', 1),\n",
       " ('V of O', 1),\n",
       " ('V as O', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dict(norm_patterns['rely']['ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['V', '_', 'O'], ['V', 'on', 'O'], -8.0, 0, 3)\n",
      "['V', '_', 'O']\n",
      "|.|\n",
      "['V', 'on', 'O']\n",
      "  Score=-8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "list1 = [\"V\", \"O\"]\n",
    "list2 = [\"V\", \"on\", \"O\"]\n",
    "\n",
    "alns = pairwise2.align.globalxs(list1, list2, -10, -0.5, gap_char=['_'])\n",
    "for a in alns:\n",
    "    print(a)\n",
    "    print(pairwise2.format_alignment(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
