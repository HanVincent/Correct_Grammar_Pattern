{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from Bio import pairwise2\n",
    "from utils.syntax import *\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "import json, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # ('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read patterns/sents json file\n",
    "with open('static/data/coca.patterns.slim.json', 'r', encoding='utf8') as fs:\n",
    "    content = json.load(fs)\n",
    "    patterns, sents, ngrams = content['patterns'], content['sents'], content['ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_patterns = defaultdict(lambda: defaultdict(Counter))\n",
    "norm_ngrams = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: [])))\n",
    "norm_sents = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: [])))\n",
    "\n",
    "for headword in patterns:\n",
    "    for dep in patterns[headword]:\n",
    "        for ptn in patterns[headword][dep]:\n",
    "            norm_patterns[headword][dep][normalize(ptn)] += patterns[headword][dep][ptn]\n",
    "            norm_ngrams[headword][dep][normalize(ptn)].extend(ngrams[headword][dep][ptn])\n",
    "            norm_sents[headword][dep][normalize(ptn)].extend(sents[headword][dep][ptn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 ptn / first_ptn 百分比\n",
    "def predict_ratio(ptn, patterns):\n",
    "    if ptn not in patterns: \n",
    "        return 0\n",
    "    return patterns[ptn] / patterns[max(patterns, key=patterns.get)]\n",
    "    \n",
    "CONFIDENT, UNCONFIDENT = 0.2, 0.1\n",
    "\n",
    "def categorize(ratio):\n",
    "    if ratio > CONFIDENT:     return 'right'\n",
    "    elif ratio < UNCONFIDENT: return 'wrong'\n",
    "    else:                     return 'not_sure'\n",
    "    \n",
    "    \n",
    "def get_template(ratio):\n",
    "    if ratio > CONFIDENT:     return '{{+{}//{}+}}'\n",
    "    elif ratio < UNCONFIDENT: return '[-{}//{}-]'\n",
    "    else:                     return '\\\\*{}//{}*\\\\'\n",
    "    \n",
    "    \n",
    "def suggest_ptns(bad_ptn, all_ptns, k=5):\n",
    "    ptns = truncate_k(all_ptns, all_ptns[bad_ptn]) if bad_ptn in all_ptns else all_ptns # Optimize if exist\n",
    "    \n",
    "    if len(ptns) == 0:\n",
    "        return [ptn for ptn, ctn in all_ptns.most_common(k)]\n",
    "        \n",
    "    sim_ptns = sorted(ptns, key=ptns.get, reverse=True)\n",
    "    sim_ptns = sorted(sim_ptns, key=lambda ptn: edit_distance(bad_ptn.split(' '), ptn.split(' ')))\n",
    "    \n",
    "#     print(sim_ptns[:k])\n",
    "    \n",
    "    return sim_ptns[:k]\n",
    "\n",
    "\n",
    "def suggest_ngrams(ngram, ngrams):\n",
    "    ngrams = filter(lambda ng: '@@@' not in ng, set(ngrams)) # workaround\n",
    "    ngram = ngram.lower()\n",
    "\n",
    "    sim_ngrams = sorted(ngrams, key=lambda ng: edit_distance(ngram.split(' '), ng.split(' ')))\n",
    "    \n",
    "    return sim_ngrams[:3]\n",
    "\n",
    "\n",
    "def edit_ngram(tk, ngram_list, old_ptn, new_ptn):\n",
    "    edit_ngram_list = [ng.text for ng in ngram_list]\n",
    "    old_ptn, new_ptn = old_ptn.split(' '), new_ptn.split(' ')\n",
    "    align = pairwise2.align.globalxs(old_ptn, new_ptn, -10, -0.5, gap_char=['_'])[0]\n",
    "    anchor = [i for i, ng in enumerate(ngram_list) if ng.i == tk.i][0]\n",
    "    \n",
    "    for i, tag in enumerate(align[1]):\n",
    "        if tag in ['S', 'V', 'O']: \n",
    "            pass\n",
    "        elif tag in PREPOSITIONS and edit_ngram_list[i+anchor] in PREPOSITIONS: \n",
    "            edit_ngram_list[i + anchor] = tag\n",
    "        elif tag in PREPOSITIONS:\n",
    "            edit_ngram_list[i + anchor] = tag + ' ' + edit_ngram_list[i + anchor]\n",
    "        elif tag == '_': \n",
    "            edit_ngram_list[i + anchor] = None\n",
    "        else:\n",
    "            print(\"Not here:\", tag)\n",
    "\n",
    "    return ' '.join([ng for ng in edit_ngram_list if ng])\n",
    "\n",
    "\n",
    "def edit_sentence():\n",
    "    pass\n",
    "\n",
    "\n",
    "def edit(line):\n",
    "    line = nlp(line)\n",
    "    \n",
    "    edits, meta = [], {}\n",
    "    for i, tk in enumerate(line):\n",
    "        if tk.tag_ in POS['VERB']:\n",
    "            ptns, ngrams = dep_to_ptns_ngrams(tk)\n",
    "            ptn, ngram = ' '.join(ptns), ' '.join(ngrams)\n",
    "            \n",
    "            norm_ptn = normalize(ptn)\n",
    "            ptns = norm_patterns[tk.lemma_][tk.dep_]            \n",
    "            ratio = predict_ratio(norm_ptn, ptns)\n",
    "        \n",
    "            meta[str(i)]={\n",
    "                'lemma': tk.lemma_,\n",
    "                'dep': tk.dep_,\n",
    "                'bef': norm_ptn,\n",
    "                'ngram': ngram\n",
    "            }\n",
    "\n",
    "            edits.append(get_template(ratio).format(tk.text, i))\n",
    "        else:\n",
    "            edits.append(tk.text)\n",
    "   \n",
    "    return ' '.join(edits), meta\n",
    "\n",
    "\n",
    "def suggest_info(data):\n",
    "    info = []\n",
    "    ptns = suggest_ptns(data['bef'], norm_patterns[data['lemma']][data['dep']])\n",
    "    \n",
    "    total = sum(norm_patterns[data['lemma']][data['dep']].values())\n",
    "    for ptn in ptns:\n",
    "        ngrams = suggest_ngrams(data['ngram'], norm_ngrams[data['lemma']][data['dep']][ptn])\n",
    "#         ngrams = Counter(norm_ngrams[data['lemma']][data['dep']][ptn]).most_common(3)\n",
    "        per = norm_patterns[data['lemma']][data['dep']][ptn] / total\n",
    "    \n",
    "        if per < 0.01: continue\n",
    "    \n",
    "        info.append({'ptn': ptn, 'percent': math.floor(per*100),'ngrams': ngrams})\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from pprint import pprint\n",
    "    from utils.counts import *\n",
    "    \n",
    "#     user_input = '''I like you. \\n I want to discuss exaggerately about my life. I rely my ability.'''\n",
    "    user_input = 'can you rely heavily in my life in last July without hestitation?'\n",
    "    print(edit(user_input))\n",
    "    print()\n",
    "    pprint(suggest_info({'tk': 'discuss', 'ngram': 'to discuss about life', 'bef': 'V about O', 'dep': 'xcomp', 'lemma': 'discuss'}))\n",
    "    pprint(suggest_info({'bef': 'V to-v', 'dep': 'ROOT', 'ngram': 'I want discuss', 'lemma': 'want'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from flask_cors import CORS, cross_origin\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "# post /correct data: { content: str }\n",
    "@app.route('/correct', methods=['POST'])\n",
    "def correct():\n",
    "    request_data = request.get_json()\n",
    "    if not request_data: return jsonify({'edit': 'Should not be empty'})\n",
    "    \n",
    "    content = request_data['content']\n",
    "    print(content)\n",
    "        \n",
    "    edit_line, meta = edit(content)\n",
    "\n",
    "    return jsonify({'edit': edit_line, 'meta': meta})\n",
    "\n",
    "\n",
    "# post /suggest data: {'tk': 'want', 'bef': 'V to-v', 'dep': 'ROOT', 'lemma': 'want'}\n",
    "@app.route('/suggest', methods=['POST'])\n",
    "def suggest():\n",
    "    request_data = request.get_json()\n",
    "    if not request_data: return jsonify({'edit': 'Should not be empty'})\n",
    "    \n",
    "    print(request_data)\n",
    "    \n",
    "    return jsonify({'info': suggest_info(request_data)})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=1315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
