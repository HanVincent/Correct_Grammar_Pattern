{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from operator import itemgetter\n",
    "from utils.syntax import *\n",
    "import numpy as np\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # ('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read patterns/sents json file\n",
    "with open('coca_sm.json', 'r', encoding='utf8') as fs:\n",
    "    BNC = json.load(fs)\n",
    "    patterns, sents, ngrams = BNC['patterns'], BNC['sents'], BNC['ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepositions = ['about', 'across', 'against', 'along', 'among', 'around', 'as', 'at',\n",
    "                'beside', 'besides', 'between', 'by', 'down', 'during', \n",
    "                'except', 'for', 'from', 'in', 'inside', 'into', 'of', 'off', \n",
    "                'on', 'onto', 'outside', 'over', 'through', 'to', 'toward', 'towards', \n",
    "                'under', 'underneath', 'until', 'up', 'upon', 'with', 'within', 'without']\n",
    "# not inlcuded: above / behind / beneath /beyond / below ... \n",
    "\n",
    "def normalize(ptn):\n",
    "    if 'be V-ed' in ptn: print(ptn)\n",
    "            \n",
    "    ptn = 'V' + ptn.split('V')[1] # 去頭 (headword 之前的)\n",
    "    ptn = ' '.join(ptn.split(' ')[:4]) # max lenght: 4-gram\n",
    "    ptn = ptn.replace('V-ing', 'V').replace('V-ed', 'V') # 除了被動外，完成式和進行式改成原 V\n",
    "    ptn = ptn.replace('wh-cl', 'O').replace('cl', 'O').replace('to-v', 'O').replace('v-ing', 'O') # 將子句/動名詞/to-V 視為受詞\n",
    "        \n",
    "    ptn = ptn.split(' ')\n",
    "    if len(ptn) > 2:\n",
    "        if ptn[1] in prepositions: # V prep. _\n",
    "            ptn = ptn[:3]\n",
    "        elif ptn[1] != 'O': # V before/during O\n",
    "            ptn = ptn[:1]\n",
    "        elif ptn[2] in prepositions: # V O prep. O\n",
    "            ptn = ptn[:4]\n",
    "        else: # V O O / V O not_prep\n",
    "            ptn = ptn[:2]\n",
    "    return ' '.join(ptn)\n",
    "\n",
    "\n",
    "norm_patterns = defaultdict(lambda: defaultdict(Counter))\n",
    "norm_ngrams = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: [])))\n",
    "norm_sents = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: [])))\n",
    "\n",
    "for headword in patterns:\n",
    "    for dep in patterns[headword]:\n",
    "        for ptn in patterns[headword][dep]:\n",
    "            norm_patterns[headword][dep][normalize(ptn)] += patterns[headword][dep][ptn]\n",
    "            norm_ngrams[headword][dep][normalize(ptn)].extend(ngrams[headword][dep][ptn])\n",
    "            norm_sents[headword][dep][normalize(ptn)].extend(sents[headword][dep][ptn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_freq(counts):\n",
    "    values = list(counts.values())\n",
    "    total, avg, std = np.sum(values), np.mean(values), np.std(values)\n",
    "    # print(\"Total: {}, Avg: {}, Std: {}\".format(total, avg, std))\n",
    "\n",
    "    return dict([(ptn, count) for ptn, count in counts.items() if count > avg + std])\n",
    "\n",
    "\n",
    "def truncate_k(counts, k=10):\n",
    "    return dict([(ptn, count) for ptn, count in counts.items() if count > k])\n",
    "\n",
    "\n",
    "def sort_dict(counts):\n",
    "    return sorted(counts.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratio(ptn, patterns):\n",
    "    if ptn not in patterns: \n",
    "        return 0\n",
    "    \n",
    "    # 使用 ptn / first_ptn 百分比\n",
    "    return patterns[ptn] / patterns[max(patterns, key=patterns.get)]\n",
    "    \n",
    "    # if ptn == max(patterns, key=patterns.get): # 保證對\n",
    "    #    return 1\n",
    "    # return patterns[ptn] / sum(patterns.values())\n",
    "\n",
    "    \n",
    "CONFIDENT, UNCONFIDENT = 0.2, 0.1\n",
    "\n",
    "def categorize(ratio):\n",
    "    if ratio > CONFIDENT:     return 'right'\n",
    "    elif ratio < UNCONFIDENT: return 'wrong'\n",
    "    else:                     return 'not_sure'\n",
    "    \n",
    "    \n",
    "def get_template(ratio):\n",
    "    if ratio > CONFIDENT:     return '{{+{}+}}'\n",
    "    elif ratio < UNCONFIDENT: return '[-{}-]'\n",
    "    else:                     return '\\\\*{}*\\\\'\n",
    "    \n",
    "    \n",
    "\n",
    "def suggest_ptn(bad_ptn, ptns):\n",
    "    ptns = truncate_k(ptns, ptns[bad_ptn]) if bad_ptn in ptns else ptns # Optimize if exist\n",
    "\n",
    "    sim_ptns = sorted(ptns, key=ptns.get, reverse=True)\n",
    "    sim_ptns = sorted(sim_ptns, key=lambda ptn: edit_distance(bad_ptn.split(' '), ptn.split(' ')))\n",
    "    \n",
    "    print(sim_ptns[:10])\n",
    "    \n",
    "    return sim_ptns[0]\n",
    "\n",
    "\n",
    "def correct(line):\n",
    "    edits, suggestions = [], []\n",
    "    for tk in nlp(line):\n",
    "        if tk.tag_ in VERBS:\n",
    "            # 以下拆 def ?\n",
    "            ptn, ngram = dep_to_pattern(tk)\n",
    "\n",
    "            ptn = normalize(ptn)\n",
    "            ptns = norm_patterns[tk.lemma_][tk.dep_]\n",
    "            # high_ptns  = get_high_freq(ptns)\n",
    "            \n",
    "            ratio = predict_ratio(ptn, ptns)\n",
    "            print(tk.text, tk.dep_, ptn, ratio)\n",
    "        \n",
    "            if ratio < CONFIDENT:\n",
    "                top_ptn = suggest_ptn(ptn, ptns)\n",
    "                top_ngram = ngrams[tk.lemma_][tk.dep_][top_ptn][0]\n",
    "                suggestions.append({\n",
    "                    'category': categorize(ratio),\n",
    "                    'tk': tk.text,\n",
    "                    'bef': ptn,\n",
    "                    'aft': top_ptn,\n",
    "                    'ngram': top_ngram\n",
    "                })\n",
    "                \n",
    "            edits.append(get_template(ratio).format(tk.text))\n",
    "        else:\n",
    "            edits.append(tk.text)\n",
    "   \n",
    "    return ' '.join(edits), suggestions\n",
    "\n",
    "def main_process(content):\n",
    "    edit_lines, suggestions = [], []\n",
    "\n",
    "    for line in content.split('\\n'):\n",
    "        edit, sug = correct(line)\n",
    "        \n",
    "        edit_lines.append(edit)\n",
    "        suggestions.extend(sug)\n",
    "\n",
    "    return edit_lines, suggestions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want ROOT V O 1.0\n",
      "discuss xcomp V about O 0\n",
      "['V O', 'V with O', 'V in O', 'V for O', 'V during O', 'V among O', 'V to O', 'V at O', 'V', 'V O with O']\n",
      "rely ROOT V O 0.01032448377581121\n",
      "['V on O', 'V upon O']\n",
      "(['I {+want+} to [-discuss-] about my life . I [-rely-] my ability .'],\n",
      " [{'aft': 'V O',\n",
      "   'bef': 'V about O',\n",
      "   'category': 'wrong',\n",
      "   'ngram': 'discuss pros',\n",
      "   'tk': 'discuss'},\n",
      "  {'aft': 'V on O',\n",
      "   'bef': 'V O',\n",
      "   'category': 'wrong',\n",
      "   'ngram': 'rely on telescopes',\n",
      "   'tk': 'rely'}])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from pprint import pprint\n",
    "    user_input = '''I want to discuss about my life. I rely my ability.'''\n",
    "    pprint(main_process(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:1314/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug: * Running on http://0.0.0.0:1314/ (Press CTRL+C to quit)\n",
      "140.114.77.132 - - [10/Jun/2018 23:03:29] \"\u001b[37mOPTIONS /correct HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:140.114.77.132 - - [10/Jun/2018 23:03:29] \"\u001b[37mOPTIONS /correct HTTP/1.1\u001b[0m\" 200 -\n",
      "140.114.77.132 - - [10/Jun/2018 23:03:29] \"\u001b[37mPOST /correct HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:140.114.77.132 - - [10/Jun/2018 23:03:29] \"\u001b[37mPOST /correct HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to discuss about my life. I rely my ability. I am able to do something. I love to apple. I love to do something.\n",
      "want ROOT V O 1.0\n",
      "discuss xcomp V about O 0\n",
      "['V O', 'V with O', 'V in O', 'V for O', 'V during O', 'V among O', 'V to O', 'V at O', 'V', 'V O with O']\n",
      "rely ROOT V O 0.01032448377581121\n",
      "['V on O', 'V upon O']\n",
      "am ROOT V 1.0\n",
      "do xcomp V O 1.0\n",
      "love ROOT V to O 0.003084763948497854\n",
      "['V O', 'V O to O', 'V', 'V O for O', 'V O with O', 'V O in O']\n",
      "love ROOT V O 1.0\n",
      "do xcomp V O 1.0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS, cross_origin\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return 'Hello World'\n",
    "\n",
    "# post /correct data: {content :}\n",
    "@app.route('/correct' , methods=['POST'])\n",
    "def start_correct():\n",
    "    request_data = request.get_json()\n",
    "    if not request_data: return jsonify({'edit': 'Should not be empty'})\n",
    "    \n",
    "    content = request_data['content']\n",
    "    print(content)\n",
    "    \n",
    "    edits, suggestions = main_process(content)\n",
    "    \n",
    "    return jsonify({\n",
    "        'edits': edits,\n",
    "        'suggestions': suggestions\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=1314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
